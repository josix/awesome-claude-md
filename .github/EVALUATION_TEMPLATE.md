# Evaluation Template for CLAUDE.md Examples

Use this template to evaluate potential submissions against our [curation criteria](CRITERIA.md).

## Basic Information

**Repository**: [GitHub URL]  
**CLAUDE.md**: [Direct link to file]  
**Category**: [Proposed category]  
**Evaluator**: [Your name/handle]  
**Date**: [Evaluation date]  

## Quick Screening

- [ ] Repository has appropriate license (MIT, Apache 2.0, etc.)
- [ ] CLAUDE.md file is publicly accessible  
- [ ] Repository shows active maintenance (commits within 12 months)
- [ ] No obvious licensing or copyright issues
- [ ] No duplicate of existing example in collection

## Detailed Scoring

### 1. Repository Quality & Recognition (0-25 points)

**Stars/Recognition**: [Current star count or organization name]  
**Maintenance**: [Last commit date and activity level]  
**Production Usage**: [Evidence of real-world usage]  
**Community**: [Issue activity, discussions, etc.]  

**Score**: ___/25  
**Notes**: [Brief justification for score]

### 2. CLAUDE.md Content Quality (0-30 points)

#### Architecture & Context (0-10 points)
- System overview provided: [ ] Yes [ ] Partial [ ] No
- Component relationships clear: [ ] Yes [ ] Partial [ ] No  
- Technical context complete: [ ] Yes [ ] Partial [ ] No

**Score**: ___/10

#### Development Workflow (0-10 points)  
- Command reference included: [ ] Yes [ ] Partial [ ] No
- Environment setup documented: [ ] Yes [ ] Partial [ ] No
- Testing procedures described: [ ] Yes [ ] Partial [ ] No

**Score**: ___/10

#### Technical Depth (0-10 points)
- Detailed explanations provided: [ ] Yes [ ] Partial [ ] No
- Code examples included: [ ] Yes [ ] Partial [ ] No
- Specific patterns demonstrated: [ ] Yes [ ] Partial [ ] No

**Score**: ___/10

**Content Quality Total**: ___/30

### 3. AI Assistant Effectiveness (0-25 points)

#### Information Structure (0-10 points)
- Logical organization: [ ] Excellent [ ] Good [ ] Acceptable [ ] Poor
- Clear sections: [ ] Excellent [ ] Good [ ] Acceptable [ ] Poor
- Consistent formatting: [ ] Excellent [ ] Good [ ] Acceptable [ ] Poor

**Score**: ___/10

#### Actionable Instructions (0-10 points)
- Commands are specific: [ ] Excellent [ ] Good [ ] Acceptable [ ] Poor
- Procedures are executable: [ ] Excellent [ ] Good [ ] Acceptable [ ] Poor
- Instructions are clear: [ ] Excellent [ ] Good [ ] Acceptable [ ] Poor

**Score**: ___/10

#### Context Completeness (0-5 points)
- Sufficient context for AI: [ ] Complete [ ] Good [ ] Adequate [ ] Poor

**Score**: ___/5

**AI Effectiveness Total**: ___/25

### 4. Educational Value (0-20 points)

#### Unique Patterns & Techniques (0-10 points)
List specific techniques demonstrated:
1. [Technique 1]
2. [Technique 2] 
3. [Technique 3]

Innovation level: [ ] Highly innovative [ ] Some unique elements [ ] Standard practices [ ] Nothing distinctive

**Score**: ___/10

#### Learning Potential (0-10 points)
- Practical applications: [ ] High [ ] Medium [ ] Low
- Transferable concepts: [ ] High [ ] Medium [ ] Low
- Educational clarity: [ ] High [ ] Medium [ ] Low

**Score**: ___/10

**Educational Value Total**: ___/20

## Final Assessment

**Total Score**: ___/100

**Recommendation**:
- [ ] **Include** (85+ points) - Exceptional quality, immediate inclusion
- [ ] **Strong Candidate** (70-84 points) - Review for inclusion
- [ ] **Conditional** (55-69 points) - Needs improvement or special consideration
- [ ] **Reject** (Below 55 points) - Does not meet quality standards

### Category Fit Assessment
Does this example fit well in the proposed category?
- [ ] Perfect fit
- [ ] Good fit  
- [ ] Alternative category suggested: [Category name]
- [ ] Does not fit established categories

### Uniqueness Assessment
- [ ] Adds unique value not covered by existing examples
- [ ] Some overlap but brings new perspective
- [ ] Too similar to existing example: [Example name]

## Key Learning Points

What would developers learn from this example?

1. **[Learning Point 1]**: [Description]
2. **[Learning Point 2]**: [Description]  
3. **[Learning Point 3]**: [Description]

## Recommended Analysis Focus

If accepted, the analysis.md should emphasize:

- [Key technique or pattern to highlight]
- [Specific implementation detail to explain]
- [Best practice to emphasize]

## Additional Notes

[Any other observations, concerns, or recommendations]

---

**Evaluation completed by**: [Name]  
**Date**: [Date]  
**Next steps**: [What happens next - acceptance, feedback needed, etc.]